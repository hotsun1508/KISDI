{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b181684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "# --- 1. ë“œë¼ì´ë²„ ì„¤ì • ë° ë³€ìˆ˜ ì§€ì • ---\n",
    "company_name = '(ì£¼)ì¹´ì¹´ì˜¤í˜ì´'\n",
    "job_data = [] # ëª¨ë“  í˜ì´ì§€ì˜ ì±„ìš© ì •ë³´ë¥¼ ëˆ„ì í•  ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "try:\n",
    "    # --- 2. ì´ˆê¸° í˜ì´ì§€ ì´ë™ ë° ê²€ìƒ‰, íƒ­ í´ë¦­ ê³¼ì • ---\n",
    "    # (ì´ì „ ë‹¨ê³„ë“¤ê³¼ ë™ì¼)\n",
    "    driver.get('https://www.jobkorea.co.kr/')\n",
    "    print(\"1. ì¡ì½”ë¦¬ì•„ ì‚¬ì´íŠ¸ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    search_box = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'stext')))\n",
    "    search_box.clear()\n",
    "    search_box.send_keys(company_name)\n",
    "    \n",
    "    search_button = driver.find_element(By.ID, 'common_search_btn')\n",
    "    search_button.click()\n",
    "    print(f\"2. '{company_name}'ì„/ë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    time.sleep(3)\n",
    "\n",
    "    search_keyword = company_name.replace('(ì£¼)', '').strip()\n",
    "    print(f\"3. ê²€ìƒ‰ ê²°ê³¼ì—ì„œ '{search_keyword}' ê¸°ì—… ì •ë³´ ë§í¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\")\n",
    "    company_link_xpath = (\n",
    "        f\"//a[@data-sentry-component='Title' and contains(., '{search_keyword}')]\"\n",
    "        f\"/parent::div/preceding-sibling::div//a[contains(., '{search_keyword}')]\"\n",
    "    )\n",
    "    company_link = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, company_link_xpath)))\n",
    "    company_link.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    print(\"4. ìƒˆë¡œ ì—´ë¦° íƒ­ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.\")\n",
    "    driver.switch_to.window(driver.window_handles[-1])\n",
    "    \n",
    "    print(\"5. 'ê¸°ì—…ì •ë³´' ë²„íŠ¼ì„ í´ë¦­í•©ë‹ˆë‹¤.\")\n",
    "    company_info_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//a[contains(@class, 'girBtn') and .//span[text()='ê¸°ì—…ì •ë³´']]\"))\n",
    "    )\n",
    "    company_info_button.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    print(\"6. ìƒˆë¡œ ì—´ë¦° 'ê¸°ì—…ì •ë³´ ìƒì„¸' íƒ­ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.\")\n",
    "    driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "    print(\"7. 'ì±„ìš©' íƒ­ì„ í´ë¦­í•©ë‹ˆë‹¤.\")\n",
    "    recruit_tab_xpath = \"//a[contains(@class, 'company-nav-item') and .//div[@class='name' and text()='ì±„ìš©']]\"\n",
    "    recruit_tab = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, recruit_tab_xpath)))\n",
    "    recruit_tab.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    print(\"8. 'ì „ì²´' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ëª¨ë“  ê³µê³ ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\")\n",
    "    all_jobs_button_xpath = \"//a[contains(@class, 'btnSort') and starts-with(normalize-space(.), 'ì „ì²´')]\"\n",
    "    all_jobs_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, all_jobs_button_xpath)))\n",
    "    all_jobs_button.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    \n",
    "    page_num = 1\n",
    "    while True:\n",
    "        print(f\"9. ê° í˜ì´ì§€ë§ˆë‹¤ ê³µê³  í¬ë¡¤ë§ \\n--- {page_num} í˜ì´ì§€ í¬ë¡¤ë§ ì‹œì‘ ---\")\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        job_list_container = soup.select_one(\"div.list.clear\")\n",
    "        if not job_list_container:\n",
    "            print(\"   ê³µê³  ëª©ë¡ ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "            \n",
    "        job_items = job_list_container.select(\"div.list-item\")\n",
    "        if not job_items:\n",
    "            print(\"   í•´ë‹¹ í˜ì´ì§€ì— ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            break\n",
    "\n",
    "        print(f\"   {len(job_items)}ê°œì˜ ê³µê³ ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.\")\n",
    "        for item in job_items:\n",
    "            status = \"ë§ˆê°\" if 'end' in item.get('class', []) else \"ì§„í–‰ì¤‘\"\n",
    "            title = item.select_one(\"dt.tit\").get_text(strip=True) if item.select_one(\"dt.tit\") else \"\"\n",
    "            conditions = item.select_one(\"dd.trm\").get_text(separator=' / ', strip=True) if item.select_one(\"dd.trm\") else \"\"\n",
    "            deadline = item.select_one(\"dd.func > span.day\").get_text(strip=True) if item.select_one(\"dd.func > span.day\") else \"\"\n",
    "            job_category = item.select_one(\"dd.sub\").get_text(strip=True) if item.select_one(\"dd.sub\") else \"\"\n",
    "            link_tag = item.select_one(\"a\")\n",
    "            link = \"https://www.jobkorea.co.kr\" + link_tag['href'] if link_tag else \"\"\n",
    "\n",
    "            job_data.append({\n",
    "                \"í˜ì´ì§€\": page_num, \"ìƒíƒœ\": status, \"ê³µê³ ëª…\": title, \"ì§€ì›ìê²©\": conditions,\n",
    "                \"ë§ˆê°ì¼\": deadline, \"ì§ë¬´\": job_category, \"ìƒì„¸ë§í¬\": link\n",
    "            })\n",
    "        \n",
    "        # 'ë‹¤ìŒ' ë²„íŠ¼ ì°¾ê¸° ë° í´ë¦­\n",
    "        try:\n",
    "            # ë” ì•ˆì •ì ì¸ ì„ íƒì: í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ 'ë‹¤ìŒ' ë²„íŠ¼ì„ ì§ì ‘ ì°¾ìŒ\n",
    "            next_button_selector = \"a.tplBtn.btnPgnNext\"\n",
    "            next_button = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, next_button_selector))\n",
    "            )\n",
    "            # JavaScriptë¡œ í´ë¦­í•˜ëŠ” ê²ƒì´ ë” ì•ˆì •ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "            driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "            \n",
    "            print(f\"--- {page_num} í˜ì´ì§€ í¬ë¡¤ë§ ì™„ë£Œ. ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤. ---\")\n",
    "            page_num += 1\n",
    "            time.sleep(2) # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "            \n",
    "        except (TimeoutException, NoSuchElementException):\n",
    "            # 'ë‹¤ìŒ' ë²„íŠ¼ì„ ë” ì´ìƒ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ í˜ì´ì§€ë¡œ ê°„ì£¼í•˜ê³  ë°˜ë³µ ì¢…ë£Œ\n",
    "            print(\"\\në§ˆì§€ë§‰ í˜ì´ì§€ì…ë‹ˆë‹¤. í¬ë¡¤ë§ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
    "\n",
    "finally:\n",
    "    # --- ìµœì¢… ë‹¨ê³„: ë¸Œë¼ìš°ì € ì¢…ë£Œ ë° íŒŒì¼ ì €ì¥ ---\n",
    "    driver.quit()\n",
    "    if job_data:\n",
    "        df = pd.DataFrame(job_data)\n",
    "        file_name = f\"{company_name}_ì „ì²´ì±„ìš©ê³µê³ .csv\"\n",
    "        df.to_csv(file_name, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nğŸ‰ ì´ {len(job_data)}ê°œì˜ ê³µê³  ì •ë³´ë¥¼ '{file_name}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"\\ní¬ë¡¤ë§ëœ ë°ì´í„°ê°€ ì—†ì–´ íŒŒì¼ì„ ì €ì¥í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
